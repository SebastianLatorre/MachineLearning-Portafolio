{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Comparación"
      ],
      "metadata": {
        "id": "auHKqXAh91WM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8wLdSvU5ah0"
      },
      "outputs": [],
      "source": [
        "# Importar las bibliotecas necesarias\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import keras\n",
        "\n",
        "# Crear un DataFrame con las diferencias clave\n",
        "data = {\n",
        "    \"Característica\": [\n",
        "        \"Nivel de Abstracción\",\n",
        "        \"Facilidad de Uso\",\n",
        "        \"Modelado Dinámico vs Estático\",\n",
        "        \"Compatibilidad\",\n",
        "        \"Ecosistema\",\n",
        "        \"Soporte para Investigación\",\n",
        "        \"Despliegue en Producción\",\n",
        "        \"Desempeño\",\n",
        "        \"Comunidad y Soporte\"\n",
        "    ],\n",
        "    \"Keras\": [\n",
        "        \"Alto\",\n",
        "        \"Muy alta, API intuitiva\",\n",
        "        \"Estático (a través de TensorFlow)\",\n",
        "        \"Funciona sobre TensorFlow, Theano, y CNTK\",\n",
        "        \"Fuerte en aplicaciones de Deep Learning\",\n",
        "        \"Popular para prototipos rápidos\",\n",
        "        \"Integrado con TensorFlow para despliegue\",\n",
        "        \"Optimizado para facilidad de uso\",\n",
        "        \"Amplia comunidad, buen soporte\"\n",
        "    ],\n",
        "    \"TensorFlow\": [\n",
        "        \"Alto a Medio\",\n",
        "        \"Moderada, curva de aprendizaje\",\n",
        "        \"Estático (TensorFlow 1.x), Dinámico (TensorFlow 2.x)\",\n",
        "        \"Soporte para múltiples lenguajes (Python, C++, JavaScript)\",\n",
        "        \"Extenso ecosistema de herramientas y aplicaciones\",\n",
        "        \"Popular en la academia y la industria\",\n",
        "        \"Altamente optimizado para despliegue en producción\",\n",
        "        \"Alto rendimiento, soporte para hardware especializado\",\n",
        "        \"Gran comunidad, soporte de Google\"\n",
        "    ],\n",
        "    \"PyTorch\": [\n",
        "        \"Medio\",\n",
        "        \"Alta, más código estilo Python\",\n",
        "        \"Dinámico\",\n",
        "        \"Soporte para múltiples lenguajes (Python, C++)\",\n",
        "        \"Enfoque en investigación y desarrollo\",\n",
        "        \"Muy popular en la comunidad investigadora\",\n",
        "        \"Usado en producción con frameworks como TorchServe\",\n",
        "        \"Rendimiento competitivo, especialmente en GPUs\",\n",
        "        \"Creciente comunidad, soporte de Facebook\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras"
      ],
      "metadata": {
        "id": "Tz_p-M2t6Ly1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Implementation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Keras Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "_7mF_CEr57M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o65SmtIc60az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cTZmF5On63B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensorflow"
      ],
      "metadata": {
        "id": "ncn9dPqt6pdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Implementation\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = tf.keras.utils.to_categorical(y_train), tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'TensorFlow Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "B0Xc4sd36qpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6PVrGivM8D_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RAFSGdF08DzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch"
      ],
      "metadata": {
        "id": "1ai8fDNa8H3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Implementation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "hUyygc9n8Hpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0gFNfSa_8Mj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = MLP()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3bUQMj_R8Qet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 10\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = correct_train / total_train\n",
        "    train_acc.append(train_accuracy)\n",
        "    train_loss.append(running_loss / len(train_loader))\n",
        "\n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    val_running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            output = model(images)\n",
        "            val_loss_batch = criterion(output, labels)\n",
        "            val_running_loss += val_loss_batch.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct_val / total_val\n",
        "    val_acc.append(val_accuracy)\n",
        "    val_loss.append(val_running_loss / len(test_loader))\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {running_loss / len(train_loader)}, Validation Loss: {val_running_loss / len(test_loader)}')\n",
        "\n",
        "print(f'PyTorch Test Accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "xkSpU2-T8sdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qGrXfFgI9elM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GeZ75-zZ9hYB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}